{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835eabde-b0f9-4c27-ae30-dc0b3a02a114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "508a0b91-4dda-4805-85cc-263416cffc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voucher          0\n",
      "Seq              0\n",
      "Type             0\n",
      "Account          0\n",
      "Func Unit     9023\n",
      "Amount           0\n",
      "Currency         0\n",
      "Acctg Date       0\n",
      "Date            11\n",
      "Line #           0\n",
      "Origin           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BUSINESS CASE PART\n",
    "# Task 1\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load and merge all files Table_*\n",
    "path = 'C:/Users/lenovo/Desktop/Uday CBRE Data Analyst Assessment/Python_test'\n",
    "files = [file for file in os.listdir(path) if file.startswith('Table_') and (file.endswith('.csv') or file.endswith('.xlsx'))]\n",
    "merged_data = pd.concat([pd.read_csv(os.path.join(path, file)) if file.endswith('.csv') else pd.read_excel(os.path.join(path, file)) for file in files])\n",
    "\n",
    "\n",
    "# Step 2: Drop duplicates\n",
    "merged_data.drop_duplicates(inplace=True)\n",
    "# CSV file unable to read Ź symbol and ? was present, so replacing the ? to Ź again\n",
    "merged_data['Type'] = merged_data['Type'].replace('\\?', 'Ź', regex = True)\n",
    "\n",
    "\n",
    "# Step 3: Show number of null values in each column\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "\n",
    "# Step 4: Fill numerical null values with 1337\n",
    "numeric_columns = merged_data.select_dtypes(include=['number']).columns     # select only numerical data\n",
    "merged_data[numeric_columns] = merged_data[numeric_columns].fillna(value=1337)\n",
    "\n",
    "\n",
    "# Step 5: Calculate difference in days between Acctg Date and Date columns\n",
    "# Convert 'Acctg Date' and 'Date' columns to datetime objects with format given in dataset which is day is 1st\n",
    "merged_data['Acctg Date'] = pd.to_datetime(merged_data['Acctg Date'], errors='coerce', dayfirst=True)\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "merged_data['Date_Difference'] = (merged_data['Acctg Date'] - merged_data['Date']).dt.days.abs()     # to avoid minus(-) values used .abs()\n",
    "\n",
    "\n",
    "# Step 6: Calculate difference in BUSINESS days between Acctg Date and Date columns (ignore weekends and UK bank holidays)\n",
    "from pandas_market_calendars import get_calendar\n",
    "\n",
    "\n",
    "uk_calendar = get_calendar(\"XLON\")  # Use XLON for UK market calendar\n",
    "merged_data = merged_data.dropna(subset=['Acctg Date', 'Date'])  # Handle missing values\n",
    "\n",
    "# Used get_calendar and valid_days to calculate the business days difference for each row for UK\n",
    "merged_data['Business_Days_Difference'] = merged_data.apply(lambda row: uk_calendar.valid_days(start_date=min(row['Acctg Date'], row['Date']),\n",
    "                                                                                               end_date=max(row['Acctg Date'], row['Date'])).shape[0],\n",
    "                                                            axis=1)\n",
    "\n",
    "\n",
    "# Step 7: Convert Amount to PLN using FXrates.csv\n",
    "fx_rates = pd.read_csv(path + '/FXrates.csv')\n",
    "merged_data = pd.merge(merged_data, fx_rates, on='Currency', how='left')\n",
    "# used formula tgt_amt = src_amt * ( per usd rate of src / per usd rate of tgt)\n",
    "            #  PLN_amt = src_amt * ( per usd rate of src / per usd rate of PLN)\n",
    "merged_data['Amount_PLN'] = merged_data['Amount'] * (merged_data['Per USD'] / fx_rates.loc[fx_rates['Currency']=='PLN', 'Per USD'].values[0])\n",
    "merged_data.drop(['Per USD'],axis = 1, inplace = True)  # droppping Per Usd Column\n",
    "\n",
    "\n",
    "# Step 8: Save separate files for each unique Type value\n",
    "output_folder = 'C:/Users/lenovo/Desktop/Uday CBRE Data Analyst Assessment/Results_Pandas_Task-1'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for type_value, type_group in merged_data.groupby('Type'):\n",
    "    type_group.to_excel(f'{output_folder}/Table_{type_value}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3a0ea-b7f9-4a9c-aa3a-72a43a2b6274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b90329-1a08-4fd4-8552-dadfbe97e834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
